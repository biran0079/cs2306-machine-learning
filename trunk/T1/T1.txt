1. Convert dataset into WEKA's arrf format.
	1.1 MNIST dataset
The dataset itself is stored in binary file for the purpose of compression. To make modification of dataset easier in the future, fitst comvert it into fuman readable text file.
MNISTDataToTxt.cpp do this job. For more detail, please refer to the comment of source file.

Then convert text file into WEKA's arff file.
MNISTTxtToArff.cpp do this job. For more detail, please refer to the comment of source file.

	1.2 Semeion dataset
This dataset itself is in human readable format. So just need one step to convert it into arff fotmat.
2. C4.5 algorithm
Use J48 pachage, a C4.5 algorithm implementated in java. 


MNIST


		

TRAINING DATA:

confident factor: 0.25
percentage for validation dataset: 30%
Time taken to build model: 352.1 second
Correctly Classified on training set               97.2867%

=== Detailed Accuracy By Class ===

               TP Rate   FP Rate   Precision   Recall  F-Measure   ROC Area  Class
                 0.994     0.002      0.978     0.994     0.986      1        0
                 0.987     0.002      0.987     0.987     0.987      1        1
                 0.972     0.004      0.967     0.972     0.969      0.999    2
                 0.961     0.004      0.966     0.961     0.964      0.998    3
                 0.973     0.003      0.976     0.973     0.974      0.999    4
                 0.958     0.004      0.961     0.958     0.96       0.998    5
                 0.982     0.002      0.98      0.982     0.981      0.999    6
                 0.974     0.003      0.972     0.974     0.973      0.999    7
                 0.96      0.004      0.964     0.96      0.962      0.998    8
                 0.964     0.003      0.973     0.964     0.969      0.998    9
Weighted Avg.    0.973     0.003      0.973     0.973     0.973      0.999

2,3,5,8 are harder to clasify.

=== Confusion Matrix ===

    a    b    c    d    e    f    g    h    i    j   <-- classified as
 2943    1    4    0    2    0    5    0    5    1 |    a = 0
    1 3380    4    7    3    3    7   10    8    0 |    b = 1
   17    4 2864   12    5    6    5   22   12    1 |    c = 2
    4    8   29 2954    3   32    4   18   17    4 |    d = 3
    3    4   13    6 2847    5    5    5   13   25 |    e = 4
    9    7   15   21    4 2596   18    4   17   18 |    f = 5
    7    2    8   11    7   12 2921    0    7    0 |    g = 6
    7    6    9   15   10   10    2 3026    5   17 |    h = 7
    9    8    9   19   18   21   12    5 2761   13 |    i = 8
    8    5    8   12   19   15    1   22   19 2894 |    j = 9

Most serious confusion:
3->5
3->2
4->9
9->7
2->7

TESTING DATA:

1000 instatnces, each 785 attributes.
Correctly Classified on training set                87.67%

=== Detailed Accuracy By Class ===

               TP Rate   FP Rate   Precision   Recall  F-Measure   ROC Area  Class
                 0.953     0.01       0.91      0.953     0.931      0.977    0
                 0.957     0.009      0.929     0.957     0.943      0.979    1
                 0.874     0.017      0.859     0.874     0.866      0.931    2
                 0.835     0.018      0.838     0.835     0.836      0.922    3
                 0.864     0.013      0.877     0.864     0.87       0.927    4
                 0.789     0.016      0.828     0.789     0.808      0.885    5
                 0.907     0.009      0.915     0.907     0.911      0.952    6
                 0.906     0.012      0.893     0.906     0.9        0.956    7
                 0.798     0.018      0.828     0.798     0.813      0.88     8
                 0.865     0.014      0.871     0.865     0.868      0.927    9
Weighted Avg.    0.877     0.014      0.876     0.877     0.876      0.935

Accuracy for each digit are much lower than training dataset.
2,3,4,5,7,8,9 are harder to recognize, especially 3,5,8, similar to training dataset.


=== Confusion Matrix ===

    a    b    c    d    e    f    g    h    i    j   <-- classified as
  934    2    8    4    4    4   11    2    3    8 |    a = 0
    0 1086    6   13    2    4    8    3   13    0 |    b = 1
   15   14  902   28    8    7    8   20   26    4 |    c = 2
    8    6   32  843    7   56    2   24   25    7 |    d = 3
    9   15   15    8  848   13    9    9   16   40 |    e = 4
   12    9   15   54    9  704   19   18   25   27 |    f = 5
   23    5    7    4   11   14  869    5   18    2 |    g = 6
    1    9   28   11   17    2    1  931    9   19 |    h = 7
   18   15   30   22   23   34   23   10  777   22 |    i = 8
    6    8    7   19   38   12    0   20   26  873 |    j = 9

Most serious confusion:
3->5
5->3
4->9
9->4
8->5

Slightly different from training data set.
3<->5, 9<->4 are serious problems.


Training accuracy much higher than testing accuracy. Overfitting may exists.

Guess:
Perform more pruning may get better accuracy on testing data.
	1. Reduce confidence factor from 0.25 to 0.1, which result in more pruning. 
		Result: 
			Accuracy on training data: 96.84%, slightly lower.
			Accuracy on testing data:  87.77%, almost the same.
	2. Increase percentage of validation data from 30% to 50%.
		Result:
			Accuracy on training data: 97.2867, no change
			Accuracy on testing data:  87.67% no change
			
			



3. BayesNet algorithm

Accuracy on training data: 84.0033%
Time taken to build model: 60.67 seconds

Faster than decision tree.

TRAINING DATA:

=== Detailed Accuracy By Class ===

               TP Rate   FP Rate   Precision   Recall  F-Measure   ROC Area  Class
                 0.887     0.01       0.91      0.887     0.899      0.993    0
                 0.96      0.016      0.884     0.96      0.92       0.994    1
                 0.826     0.015      0.86      0.826     0.843      0.983    2
                 0.804     0.026      0.78      0.804     0.792      0.975    3
                 0.81      0.018      0.827     0.81      0.818      0.985    4
                 0.731     0.02       0.784     0.731     0.757      0.974    5
                 0.906     0.012      0.891     0.906     0.899      0.992    6
                 0.855     0.006      0.939     0.855     0.895      0.991    7
                 0.761     0.022      0.789     0.761     0.774      0.973    8
                 0.83      0.033      0.737     0.83      0.781      0.975    9
Weighted Avg.    0.84      0.018      0.842     0.84      0.84       0.984

Precision much lower than C4.5 Decicion tree.
3,5,8,9 are hard to classify, similar to decisoin tree.


=== Confusion Matrix ===

    a    b    c    d    e    f    g    h    i    j   <-- classified as
 2627    0   22   12    5  164   61    0   65    5 |    a = 0
    0 3287   33    9    1   41    9    1   39    3 |    b = 1
   44   46 2436   82   56   14  114   29  118    9 |    c = 2
   22   73  136 2472   13  100   22   30  115   90 |    d = 3
    8   21   25    1 2369    7   41    7   64  383 |    e = 4
   79   29   27  328   73 1980   59    6   47   81 |    f = 5
   30   65   57    1   22   92 2696    0   12    0 |    g = 6
    8   57   35    5   86    7    1 2655   50  203 |    h = 7
   35  111   41  222   40  101   20    5 2187  113 |    i = 8
   33   31   19   39  198   18    2   95   76 2492 |    j = 9

Most serious confusion:
4->9
5->3
8->3
8->9
9->4

TESTING DATA:


Accuracy: 84.84   %

=== Detailed Accuracy By Class ===

               TP Rate   FP Rate   Precision   Recall  F-Measure   ROC Area  Class
                 0.889     0.01       0.906     0.889     0.897      0.994    0
                 0.955     0.012      0.912     0.955     0.933      0.996    1
                 0.835     0.013      0.878     0.835     0.856      0.983    2
                 0.833     0.025      0.79      0.833     0.811      0.979    3
                 0.83      0.018      0.833     0.83      0.832      0.987    4
                 0.746     0.019      0.793     0.746     0.768      0.974    5
                 0.892     0.011      0.893     0.892     0.893      0.992    6
                 0.846     0.007      0.935     0.846     0.889      0.985    7
                 0.79      0.024      0.782     0.79      0.786      0.975    8
                 0.844     0.029      0.763     0.844     0.802      0.975    9
Weighted Avg.    0.848     0.017      0.85      0.848     0.849      0.984

=== Confusion Matrix ===

    a    b    c    d    e    f    g    h    i    j   <-- classified as
  871    0    7    3    2   63   16    1   16    1 |    a = 0
    0 1084   15    5    0    7    5    0   19    0 |    b = 1
   18    8  862   27   19    3   28   15   49    3 |    c = 2
    4   15   34  841    1   25    8   13   44   25 |    d = 3
    1    4    6    0  815    5   19    1   21  110 |    e = 4
   24    9    8  100   24  665   17    5   17   23 |    f = 5
   15   15   17    2   12   38  855    0    4    0 |    g = 6
    1   26   15    5   17    0    0  870   26   68 |    h = 7
   15   18   11   72   17   23    9    5  769   35 |    i = 8
   12   10    7    9   71   10    0   20   18  852 |    j = 9

Most serious confusion:
4->9
5->3
8->3
9->4
7->9


Slightly lower than training data accuracy. Lower than C4.5 algorithm.




SUMMARY: 

For both algorithm, they get similar accuracy on testing dataset.
Most comfusoin pairs of C4.5 algorithm is also likely to be funfusion pairs of BayesNet algorthm. (these pairs are also likely confuse to human)


Semeion:
Instances:    1593
Attributes:   257
Test mode:    2-fold cross-validation
Correctly Classified Instances        1161               72.8814 %

               TP Rate   FP Rate   Precision   Recall  F-Measure   ROC Area  Clas
                 0.919     0.01       0.908     0.919     0.914      0.96     0
                 0.753     0.041      0.678     0.753     0.713      0.862    1
                 0.585     0.038      0.628     0.585     0.606      0.807    2
                 0.761     0.022      0.791     0.761     0.776      0.878    3
                 0.671     0.033      0.697     0.671     0.684      0.845    4
                 0.799     0.033      0.726     0.799     0.76       0.912    5
                 0.863     0.012      0.891     0.863     0.877      0.937    6
                 0.665     0.026      0.734     0.665     0.698      0.813    7
                 0.568     0.043      0.587     0.568     0.577      0.801    8
                 0.696     0.042      0.647     0.696     0.671      0.86     9
Weighted Avg.    0.729     0.03       0.729     0.729     0.728      0.868

3,5,7,8,9 have poor accuracy.
Average accuracy is lower than MNIST. Possible reason is because not enough instances.(to be validated, test on different size of datasets)

=== Confusion Matrix ===

   a   b   c   d   e   f   g   h   i   j   <-- classified as
 148   1   3   0   4   0   0   0   3   2 |   a = 0
   0 122   8   3   7   1   1   6   3  11 |   b = 1
   3   8  93   2  11   3   3  11  24   1 |   c = 2
   0   4   7 121   1   6   0   3   7  10 |   d = 3
   6   9   6   2 108  10   3   5   3   9 |   e = 4
   1   3   2   7   5 127   1   1   2  10 |   f = 5
   2   5   2   0   2   2 139   2   6   1 |   g = 6
   1  19   6   3   6   6   5 105   4   3 |   h = 7
   0   3  20   4   5  10   4   8  88  13 |   i = 8
   2   6   1  11   6  10   0   2  10 110 |   j = 9

Most serious confusion:
2->8
8->2
7->1
8->9
9->3
