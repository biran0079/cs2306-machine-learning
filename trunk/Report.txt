Recognize handwritten digit using Decision tree and Bayes Network

Abstruct

Handwritten digits recognition is an important application of machine learning. The objective is to recognize images of handwritten digits based on classification methods for multivariate data. This paper will apply C4.5 decision tree algorithm, boosting algorithm on C4.5, support vector machine(SVM) algorithm in this paper. Semeion Handwritten Digit Data Set is used for testing.

Introduction


WEKA is be used for training and testing in this paper. Algorithms used for training and testing are provided by WEKA, or some open source packages.

DataSet

Semeion Handwritten Digit Data Set is used in this paper. The dataset was created by Tactile Srl, Brescia, Italy (http://www.tattile.it) and donated in 1994 to Semeion Research Center of Sciences of Communication, Rome, Italy (http://www.semeion.it), for machine learning research. 
1593 handwritten digits from around 80 persons were scanned, stretched in a rectangular box 16x16 in a gray scale of 256 values.Then each pixel of each image was scaled into a bolean (1/0) value using a fixed threshold. This dataset contains no missing values.
Each person wrote on a paper all the digits from 0 to 9, twice. The commitment was to write the digit the first time in the normal way (trying to write each digit accurately) and the second time in a fast way (with no accuracy). 

This dataset consists of 1593 records (rows) and 256 attributes (columns).
Each record represents a handwritten digit, orginally scanned with a resolution of 256 grays scale.
Each pixel of the each original scanned image was first stretched, and after scaled between 0 and 1 (setting to 0 every pixel whose value was under tha value 127 of the grey scale (127 included) and setting to 1 each pixel whose orinal value in the grey scale was over 127).
Finally, each binary image was scaled again into a 16x16 square box (the final 256 binary attributes). 

To convert it into WEKA accetable form without lossing information of the dataset, I modified the "class label" part into a digit from 0 to 9, and.
The dataset is given following certain order such that many instances with the same label are close to each other in the file. To avoid it's incluence, the order of instances are shuffled before being read by WEKA.

Algorithm

Decision tree (C4.5)
Decision tree is a popular machine learning algorithm. It represend a function in form of a tree, each node denote an attrribute, and each edge represent the condition which lead to the next node. Leaves contains labels, which are the result of classification. Decision tree efficient and simple. The tree can be pretty human readable, unlike some algotithms like artificial nueral network. Decision tree is very descriptive, and theoretically, decision tree can represent any function. There are many decision tree algorithms in machine learning, and the decision tree algorithm used in this paper is C4.5, an improved version of ID3 algorithm. C4.5 algorithm follows a simple inductive bias, which is "smaller trees are prefered", which means that smaller trees tend to perform bettwe than bigger trees on unseen dataset. This inductive bias is motivated by Occan Razor principle. C4.5 works well in many cases, and is one of the most popular decision tree algorithm. A free implementation of C4.5 algorithm in java is available in J48 package. J48 is also integrated in WEKA.


Performance

The data set contains 1593 instances, which is very small. So cross validation is used to perform testing. By applying cross validation on different fold number, we can see that the error rate doesnot change much after 4 fold, so the result of 4 fold cross validation is very likely to provide accurate estimation of the real error rate on the dataset. To be safe, we use 10 fold cross validation in this paper as default testing method.

Fold number	Error rate
	2	 29.0019 %
	4	 25.6121 %
	6	 24.231  %
	8	 24.6704 %
	10	 23.9799 %
	12	 24.8588 %
	14	 24.5449 %

The above result is obtained by using default parameter setting in WEKA, the error rate of C4.5 algortihm is between 24% and 25%.
However, if we apply C4.5 algorithm on the whole dataset, the error rate on the whole dataset is 5.7125 %. So there is overfitting.
This result is very poor compared to many other popular algorithms like support vector machine(will see it later in the paper). This is because the limitation of decision tree itself. Although a decision tree with no size limit can be proved to form any function. However, C4.5 algorithm's inductive bias shows that smaller trees are preferable, which potentially reduce the number candidate hypothesise, so the result decision tree may not have a very high accuracy.

It is easy to overfit the training dataset for decision trees.
C4.5 use some pruning technique to deal with the overfitting problem. 

J48 package provide several adjustable parameters for C4.5 algorithm, one of them is confident factor.
According to [Morgan.Kaufmann,.Data.Mining.Practical.Machine.Learning.Tools], confident factor is a probability threshold of the probability of the actual error rate is worse than the pessimistic estimation based on some reasonable assumption. The pessimistic estimation of the error rate for each subtree is used when do the subtree replacement and subtree raising pruning in C4.5 algorithm. So smaller confidence factor implise more pessimistic estimation, which will cause more drastic pruning. The default confident factor in WEKA is 0.25, which is a bit large for some noisy dataset.


Confident factor	Error rate	Tree size
0.30			23.9799 %	297
0.25			23.9799 %	293
0.20			23.8544 %	281
0.15			23.9171 %	281
0.10			24.231  %	277
0.05			24.231  %	267
0.01			24.4821 %	255
0.001			24.3566 %	237
1E-4			24.6077 %	213
1E-5			26.3026 %	179


We can see that although the size of the tree is reducing when confident factor decreases, the error rate doesn't decrease as expected. More over, it starts to increase when the size of tree decrease too some extent. 
So adjusting confident factor may not work for this dataset.


Another parameter which can be adjusted is the minimun number of instances per leaf(which is 2 by default). Increase this number may reduce the size of the tree, which makes the classifier more robust to noise.

Num	Error rate	Tree size
1	24.4193 %	437
2	23.9799 %	293
3	23.9799 %	229
4	24.6077 %	193
5	25.1099 %	171
6	25.8632 %	151

The result shows that the size of the tree decreases rapidly when the minimun number of instances increases. However, the error rate still doesn't change much when the tree size decreases. Considering the small size of dataset, each leaf would have about 10-20 instances on average, which is very small already. So set a large value for this parameter may not be a good idea.

Noticing that the digit only appears in the center of each image, so some pixels on the corner and edges are vary likely to be white, thus those attributes are very unlikely to provide any useful information for classification. Moreover, those attributes may bring in noise. Thus, selecting attributes of the dataset may help eliminate some noise of the dataset.

The C4.5 algorithm is build by selecting attributes with high information gain first. So we can try to select attributes based on information gain of each attribute.

Num of attribute	Error rate	Tree size
256			23.9799 %	293
200			22.1594 %	285
150			22.4105 %	301
100			25.9887 %	323
50			33.7728 %	327

The result shows that as the number of attributes decreases, the error rate first decrease slightly, and after that start to increase.
The size of the tree does not always decreases when the number of attribute decreases because only "useless attributes" which are not likely to appear in the original decision tree are discarded.

Since C4.5 algorithm itself is based on attribute selection by information gain, when constructing the decision tree, attributes are selected based on their infomation gain. So selecting attribute again does not help much, it not make things worse.



Boosting is an algorithm which can boost week classifier into a stronger classifier. The boosting alglrithm provided by WEKA is AdaBoosting M1, which is generalization of AdaBoosting algorithm on multiple class classification probelm. It requires over 50% accuracy of "week classifier" on the dataset in order to "boost" it into a stronger classifier.
The boosting algorithm constructs the classifier by several iteratrions, each iteration obtains a classifier by weighted dataset, and the output of the final classifier is obtained by weighted sum of classifiers builded in all iterations. Misclassified instances has a larger weight so that thoses instances will be paid more attention on in the next iteratiion. The weight of each classifier is decided by their accuracy. Boosting works well with decision tree in practice, and it often does not suffer from overfitting.


We apply boosting on C4.5 algorithm with different number of iterations.

Num of Iterations	Error rate
	2		24.3566 %
	4		17.1375 %
	8		12.6177 %
	16		 8.7884 %
	32		 7.5957 %
	64		 7.2819 %

We can see that although C4.5 itself performs poorly on this dataset(error rate greater than 20%), the boosted C4.5 can performs very well.
The error rate drops dramatically as the iteration number increases, and keep to about 7%.It does not appear to overfitting as the number of iteration increases.

Boosting algorithm constructs a classifier by combining several classifiers, which increase the complxity of the classifier. However, according to Occan Razor principle, easier classifiers tend to generalize better on unseen dataset. Boosting algorithm seems a cotradict with Occan Razor.
One possible explaination is that the complexity of classifier is not measured by the number of classifiers, but by the "margin" of the classifier. 
In Boosting algorithm, each classifier vote to a class by its weight, and the class with the highest weight is the result of classification. The "margin" of an example is defined by the difference between weight of correct class, and the weight of the sum of all weights of incorrect class. The larger the margin is , the more confident the classification for this instance is. The boosting algorithm tend to maximize margin of instances, and convergence with some large margin distribution. Sometimes we can observe that when running boosting algorithm, the testing error keeps on decreases even after the error rate of training set is 0. This is because when the error rate of testing data is zero, the margin distribution may not have converged yet, and as margin increases, the error rate on testing dataset decreases[Schapire,Freund,Bartlett,Lee].


Support vector machine

Introduction

Support vector machine can be seen as a generalized version of linear classifiere. To classify dataset which are not linear seperatable, SVM project each example into a higher dimensional feature space, and find a hyper plane, which seperate the dataset. The margin of hyper plane is defined as the distance of the plane to the closest example. Hyper plaine with large margin is prefered in SVM. All calculation of feature vector with high dimension can be done by kernel function, which reduce the computation time dramatically. Different kernel function can be used for different feature space. In this paper, we only use polynomial kernels.

WEKA's libsvm package implemented by Chih-Chung Chang and Chih-Jen Lin is used for testing.

Testing


Kernel			Error rate
polynomial degree 1	7.0935 %
polynomial degree 2	4.2687 %
polynomial degree 3	4.6453 %
polynomial degree 4	6.1519 %
polynomial degree 5	8.349  %

kernel function forms:
polynomial kernel: 	(u*v)^degree

The result shows that SVM gives very good result. We can observe that the error rate first increases, and then decreases as the degree of the polynomial kernel increases. This is because the hyper plain tends to be more flexible to fit the training set when the degree is larger, which can result in overfitting, especially when the dataset is limited.


Improvement

One observasion is that for decision tree and SVM, the order of attributes is not important for training and classification. In other word, if I apply some fixed permutation on the attributes of each example in the dataset, then decision tree and SVM will generate almost the same model as the model generated by original dataset.
However, the order of pixel is important in the process of human being recognizing a hand written digit. If the rearrange the pixel of an image randomly, a human is very unlikely to recognize what's in the image.
Moreover, some propertys of the dataset are harder to learn for certain classifiers(e.g. decision tree are not good at representing XOR function). 
This motivate the preprocessing of data. More specifically, we try to add some attributes which provide those information which are hard to learn by machine learning algorithms.


Features to add:

In general, 34 more features are added into each examples, so that the modified dataset has 290 features for each example.
To provide information about the position of pixels, we choose to add 16 extra attributes r[16], one for each row, which describes how many "black segments" are there in the row. In image of 1, most of r[i] can be expected to be 1, and some can be 2, depends on the way of writing. In image of 0, most r[i] can be expected to be 2.
Similarly, 16 more attributes c[16] is added for each column, which means the number of "black segments" in each column.

The varient of the number of black pixels in each row, and the varient of the number of black pixels in each column are also added into each example.


Testing

Algorithm			Original Error Rate	Error Rate On Blur Digit
C4.5				23.9799 %		18.6441 %
Boosted C4.5(8 iterations)	12.6177 %		 7.8468 %
Boosted C4.5(16 iterations)	8.7884 %		 6.5286 %
SVM(polynomial d-1 kernel)	7.0935 %		 4.2687 %
SVM(polynomial d-2 kernel)	4.2687 %		 3.7037 %
SVM(polynomial d-3 kernel)	4.6453 %		 3.892  %
SVM(polynomial d-4 kernel)	6.1519 %		 5.022  %

From the result, we can see improvements on all algorithms are significant. 34 attributes is a small number compared to original 256 attributes, so the increase in time cost is trivial. So adding extra information tend to help improve accuracy for these algorithms.


Conclusion

By applying several machine learning algorithms on Semeion Handwritten Digit Data Set, we can observe that C4.5 algorithm performs poorly, while boosted C4.5 has a much better performance. SVM performs very well with linear kernel, and even better with polymonial kernel of degree 2 and 3. By adding extra information into the dataset, the error rate for all these algorithm drops significantly, and SVM with polinomial d-2 kernel has the lowest error rate.


References
